{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Spanish data to word lists\n",
    "format Spanish in the following formats:\n",
    "\n",
    "* all data text spanish: \"word\", \"type\", \"english\", \"frequency_rank\"\n",
    "* 2 column: word, type, definiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167571/561376880.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>type</th>\n",
       "      <th>english</th>\n",
       "      <th>frequency_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>prep</td>\n",
       "      <td>to, at</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abajo</td>\n",
       "      <td>adv</td>\n",
       "      <td>down, below, downward</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonado</td>\n",
       "      <td>adj</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>2896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandonar</td>\n",
       "      <td>v</td>\n",
       "      <td>to abandon, leave (a place)</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandono</td>\n",
       "      <td>nm</td>\n",
       "      <td>abandonment, desertion</td>\n",
       "      <td>3463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  type                      english frequency_rank\n",
       "0           a  prep                       to, at              8\n",
       "0       abajo   adv        down, below, downward            788\n",
       "0  abandonado   adj                    abandoned           2896\n",
       "0   abandonar     v  to abandon, leave (a place)            680\n",
       "0    abandono    nm       abandonment, desertion           3463"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = 'spanish_5000'\n",
    "df = pd.read_pickle(f\"./data/spanish/spanish.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>type</th>\n",
       "      <th>english</th>\n",
       "      <th>frequency_rank</th>\n",
       "      <th>example_spanish</th>\n",
       "      <th>example_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>el</td>\n",
       "      <td>art</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>el diccionario tenía también frases útiles</td>\n",
       "      <td>the dictionary also had useful phrases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>prep</td>\n",
       "      <td>of, from</td>\n",
       "      <td>2</td>\n",
       "      <td>es el hijo de un amigo mío</td>\n",
       "      <td>he is the son of a friend of mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>que</td>\n",
       "      <td>conj</td>\n",
       "      <td>that, which</td>\n",
       "      <td>3</td>\n",
       "      <td>dice que no quiere estudiar</td>\n",
       "      <td>he says that he doesn’t want to study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>conj</td>\n",
       "      <td>and</td>\n",
       "      <td>4</td>\n",
       "      <td>saben leer y escribir</td>\n",
       "      <td>they know how to read and write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>prep</td>\n",
       "      <td>in, on</td>\n",
       "      <td>5</td>\n",
       "      <td>vivo en el segundo piso</td>\n",
       "      <td>I live on the second floor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  type      english frequency_rank  \\\n",
       "0   el   art         the               1   \n",
       "0   de  prep     of, from              2   \n",
       "0  que  conj  that, which              3   \n",
       "0    y  conj          and              4   \n",
       "0   en  prep       in, on              5   \n",
       "\n",
       "                              example_spanish  \\\n",
       "0  el diccionario tenía también frases útiles   \n",
       "0                  es el hijo de un amigo mío   \n",
       "0                 dice que no quiere estudiar   \n",
       "0                       saben leer y escribir   \n",
       "0                     vivo en el segundo piso   \n",
       "\n",
       "                          example_english  \n",
       "0  the dictionary also had useful phrases  \n",
       "0       he is the son of a friend of mine  \n",
       "0   he says that he doesn’t want to study  \n",
       "0         they know how to read and write  \n",
       "0              I live on the second floor  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_pickle(f\"./data/spanish/spanish2.pkl\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"word\": word, \"type\": type, \"english\": english, \"frequency_rank\": frequency_rank\n",
    "def load_data():\n",
    "    data = df[[\"word\", \"type\", \"english\", \"frequency_rank\"]]\n",
    "    #data = data.rename(columns={'english' : 'English'})\n",
    "    #data = data.rename(columns={'frequency_rank' : 'frequency rank'})\n",
    "    return data\n",
    "\n",
    "# \"word\": word, \"type\": type, \"english\": english, \"frequency_rank\": frequency_rank, \"example_spanish\": example_spanish, \"example_english\": example_english\n",
    "def load_data2():\n",
    "    data = df2[[\"word\", \"type\", \"english\", \"example_spanish\", \"example_english\", \"frequency_rank\"]]\n",
    "    #data = data.rename(columns={'english' : 'English'})\n",
    "    #data = data.rename(columns={'spanish' : 'Spanish'})\n",
    "    #data = data.rename(columns={'frequency_rank' : 'frequency rank'})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import load_spanish2 as load_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import replace_word_in_field_with_underscore as replace_word_in_field_with_underscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML+PDF all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: unknown option '--enable-local-file-access'\n",
      "Error producing PDF.\n",
      "\n",
      "error: unknown option '--enable-local-file-access'\n",
      "Error producing PDF.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11008"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML, Underscore, Shuffled and Alphabetical\n",
    "data = load_data2()\n",
    "\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data = data.drop(['frequency_rank'], axis=1)\n",
    "data = data.rename(columns={'example_english' : 'example (English)'})\n",
    "data = data.rename(columns={'example_spanish' : 'example (Spanish)'})\n",
    "\n",
    "data = data.sample(frac=1) # shuffle\n",
    "\n",
    "style = data.style.format(\n",
    "    escape=\"html\",\n",
    "    )\n",
    "style = style.hide(axis='index')\n",
    "\n",
    "html = style.to_html()\n",
    "filename = DATASET+'_underscore_shuffled'\n",
    "with open(f'output/{filename}.html', 'w') as f:\n",
    "    f.write('<meta charset=\"UTF-8\">'+html)\n",
    "\n",
    "cmd = f'pandoc -f html -t pdf output/{filename}.html -t html5 -o output/{filename}.pdf --metadata pagetitle=\"{filename}\" -V margin-top=1cm -V margin-bottom=1cm -V margin-left=1cm -V margin-right=1cm -c format/table.css '\n",
    "os.system(cmd)\n",
    "\n",
    "####### Sort Alphabetical\n",
    "\n",
    "data.sort_values('word') # alphabetical\n",
    "filename = DATASET + '_underscore_alphabetical'\n",
    "with open(f'output/{filename}.html', 'w') as f:\n",
    "    f.write('<meta charset=\"UTF-8\">'+html)\n",
    "cmd = f'pandoc -f html -t pdf output/{filename}.html -t html5 -o output/{filename}.pdf --metadata pagetitle=\"{filename}\" -V margin-top=1cm -V margin-bottom=1cm -V margin-left=1cm -V margin-right=1cm -c format/table.css '\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: unknown option '--enable-local-file-access'\n",
      "Error producing PDF.\n",
      "\n",
      "error: unknown option '--enable-local-file-access'\n",
      "Error producing PDF.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11008"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML, Shuffled and Alphabetical, without underscore\n",
    "data = load_data2()\n",
    "\n",
    "# data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data = data.drop(['frequency_rank'], axis=1)\n",
    "data = data.rename(columns={'example_english' : 'example (English)'})\n",
    "data = data.rename(columns={'example_spanish' : 'example (Spanish)'})\n",
    "\n",
    "data = data.sample(frac=1) # shuffle\n",
    "\n",
    "style = data.style.format(\n",
    "    escape=\"html\",\n",
    "    )\n",
    "style = style.hide(axis='index')\n",
    "\n",
    "html = style.to_html()\n",
    "filename = DATASET+'_shuffled'\n",
    "with open(f'output/{filename}.html', 'w') as f:\n",
    "    f.write('<meta charset=\"UTF-8\">'+html)\n",
    "\n",
    "cmd = f'pandoc -f html -t pdf output/{filename}.html -t html5 -o output/{filename}.pdf --metadata pagetitle=\"{filename}\" -V margin-top=1cm -V margin-bottom=1cm -V margin-left=1cm -V margin-right=1cm -c format/table.css '\n",
    "os.system(cmd)\n",
    "\n",
    "####### Sort Alphabetical\n",
    "\n",
    "data.sort_values('word') # alphabetical\n",
    "filename = DATASET + '_alphabetical'\n",
    "with open(f'output/{filename}.html', 'w') as f:\n",
    "    f.write('<meta charset=\"UTF-8\">'+html)\n",
    "cmd = f'pandoc -f html -t pdf output/{filename}.html -t html5 -o output/{filename}.pdf --metadata pagetitle=\"{filename}\" -V margin-top=1cm -V margin-bottom=1cm -V margin-left=1cm -V margin-right=1cm -c format/table.css '\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML+PDF all columns grouped by CEFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: unknown option '--enable-local-file-access'\n",
      "Error producing PDF.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Ranking / pseudo-cefr. Shuffled\n",
    "data = load_data2()\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data.head()\n",
    "\n",
    "data_by_cefr = [\n",
    "    data.iloc[:1000],\n",
    "    data.iloc[1000:2000],\n",
    "    data.iloc[2000:3000],\n",
    "    data.iloc[3000:4000],\n",
    "    data.iloc[4000:],\n",
    "    ]\n",
    "\n",
    "data_by_cefr[1].head()\n",
    "cefrs = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "\n",
    "# Complete to HTML\n",
    "html_out = ''\n",
    "for i, data_slice in enumerate(data_by_cefr):\n",
    "    if data_slice.empty:\n",
    "        continue\n",
    "    #cefr = data_slice['cefr'].iloc[0]\n",
    "    cefr = cefrs[i]\n",
    "    html_out += f'<h2>{cefr}</h2>'\n",
    "    data_slice = data_slice.drop(['frequency_rank'], axis=1)\n",
    "    data_slice = data_slice.rename(columns={'word' : f'word ({cefr})'})\n",
    "    data_slice = data_slice.rename(columns={'example_english' : 'example (English)'})\n",
    "    data_slice = data_slice.rename(columns={'example_spanish' : 'example (Spanish)'})\n",
    "\n",
    "    data_slice = data_slice.sample(frac=1) # shuffle\n",
    "\n",
    "    style = data_slice.style.format(\n",
    "        escape=\"html\",\n",
    "        )\n",
    "    style = style.hide(axis='index')\n",
    "    html_out += style.to_html()\n",
    "\n",
    "filename = DATASET+'_underscore_by_cefr_shuffled'\n",
    "with open(f'output/{filename}.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_out)\n",
    "\n",
    "# to pdf\n",
    "cmd = f\"\"\"pandoc -f html -t pdf output/{filename}.html -t html5 -o output/{filename}.pdf --metadata pagetitle=\"{filename}\" -V margin-top=2 -V margin-bottom=2 -V margin-left=2 -V margin-right=2 -c format/table.css  --title '{filename}'\"\"\"\n",
    "os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: unknown option '--enable-local-file-access'\n",
      "Error producing PDF.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11008"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By Ranking / pseudo-cefr. Alphabetical\n",
    "data = load_data2()\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data.head()\n",
    "\n",
    "data_by_cefr = [\n",
    "    data.iloc[:1000], #A1\n",
    "    data.iloc[1000:2000], #A2\n",
    "    data.iloc[2000:3000], #B1\n",
    "    data.iloc[3000:4000], #B2\n",
    "    data.iloc[4000:], #C1\n",
    "    ]\n",
    "\n",
    "data_by_cefr[1].head()\n",
    "cefrs = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "\n",
    "# Complete to HTML\n",
    "html_out = ''\n",
    "for i, data_slice in enumerate(data_by_cefr):\n",
    "    if data_slice.empty:\n",
    "        continue\n",
    "    cefr = cefrs[i]\n",
    "    html_out += f'<h2>{cefr}</h2>'\n",
    "    data_slice = data_slice.drop(['frequency_rank'], axis=1)\n",
    "    data_slice = data_slice.sort_values('word')\n",
    "    data_slice = data_slice.rename(columns={'word' : f'word ({cefr})'})\n",
    "    data_slice = data_slice.rename(columns={'example_english' : 'example (English)'})\n",
    "    data_slice = data_slice.rename(columns={'example_spanish' : 'example (Spanish)'})\n",
    "\n",
    "    style = data_slice.style.format(\n",
    "        escape=\"html\",\n",
    "        )\n",
    "    style = style.hide(axis='index')\n",
    "    html_out += style.to_html()\n",
    "\n",
    "filename = DATASET+'_underscore_by_cefr_alphabetical'\n",
    "with open(f'output/{filename}.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_out)\n",
    "\n",
    "# to pdf\n",
    "cmd = f\"\"\"pandoc -f html -t pdf output/{filename}.html -t html5 -o output/{filename}.pdf --metadata pagetitle=\"{filename}\" -V margin-top=2 -V margin-bottom=2 -V margin-left=2 -V margin-right=2 -c format/table.css  --title '{filename}'\"\"\"\n",
    "os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Column LateX word, type and definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import FixLatexLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rc files read:\n",
      "  /etc/LatexMk\n",
      "Latexmk: This is Latexmk, John Collins, 4 Apr. 2023. Version 4.80.\n",
      "Latexmk: Changing directory to 'format/'\n",
      "Latexmk: Undoing directory change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "Latexmk: Could not find file 'spanish_5000_two_column_alphabetical.tex'.\n",
      "-- Use the -f option to force complete processing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rc files read:\n",
      "  /etc/LatexMk\n",
      "Latexmk: This is Latexmk, John Collins, 4 Apr. 2023. Version 4.80.\n",
      "Latexmk: Changing directory to 'format/'\n",
      "Latexmk: Undoing directory change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "Latexmk: Could not find file 'spanish_5000_two_column_shuffle.tex'.\n",
      "-- Use the -f option to force complete processing.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2816"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 column 5000 not by rank\n",
    "# shuffle and alphabetical\n",
    "import re\n",
    "# Fix supertabular and add \\textit to type\n",
    "column_format = 'p{1.2in}p{2.3in}p{1.2in}p{2.3in}'\n",
    "fix_latex_line = FixLatexLine(column_format).fix_latex_line\n",
    "\n",
    "# columns = [\"word\", \"type\", \"english\", \"frequency_rank\"]\n",
    "data = load_data2()\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data[\"word\"] = data.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
    "#data = data[[\"word\", \"spanish\", \"english\", \"example_spanish\", \"example_english\"]]\n",
    "data = data[[\"word\", \"english\"]]\n",
    "\n",
    "style = data.style.format(\n",
    "    escape=\"latex\",\n",
    "    )\n",
    "style = style.hide(axis='index')\n",
    "style = style.hide(axis='columns')\n",
    "\n",
    "\n",
    "latex = style.to_latex(\n",
    "    environment='supertabular',\n",
    "    column_format=column_format\n",
    ")\n",
    "\n",
    "latex_lines = latex.splitlines()\n",
    "\n",
    "latex = '\\n'.join((map(fix_latex_line, latex_lines)))\n",
    "\n",
    "with open(f'build/{DATASET}_two_column_alphabetical.tex', 'w') as f:\n",
    "    f.write(latex)\n",
    "\n",
    "cmd_build = f\"latexmk -pdf -cd format/{DATASET}_two_column_alphabetical.tex -outdir=../output\"\n",
    "os.system(cmd_build)\n",
    "\n",
    "#### Same for shuffle\n",
    "\n",
    "data = data.sample(frac=1) # shuffle\n",
    "style = data.style.format(\n",
    "    escape=\"latex\",\n",
    "    )\n",
    "style = style.hide(axis='index')\n",
    "style = style.hide(axis='columns')\n",
    "\n",
    "latex = style.to_latex(\n",
    "    environment='supertabular',\n",
    "    column_format=column_format\n",
    ")\n",
    "\n",
    "latex_lines = latex.splitlines()\n",
    "latex = '\\n'.join((map(fix_latex_line, latex_lines)))\n",
    "\n",
    "with open(f'build/{DATASET}_two_column_shuffle.tex', 'w') as f:\n",
    "    f.write(latex)\n",
    "\n",
    "cmd_build = f\"latexmk -pdf -cd format/{DATASET}_two_column_shuffle.tex -outdir=../output\"\n",
    "os.system(cmd_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167571/2484496685.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/2484496685.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/2484496685.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/2484496685.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/2484496685.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n"
     ]
    }
   ],
   "source": [
    "# two column, cefr by rank\n",
    "import re\n",
    "\n",
    "data = load_data2()\n",
    "data_by_cefr = [\n",
    "    data.iloc[:1000], #A1\n",
    "    data.iloc[1000:2000], #A2\n",
    "    data.iloc[2000:3000], #B1\n",
    "    data.iloc[3000:4000], #B2\n",
    "    data.iloc[4000:], #C1\n",
    "    ]\n",
    "\n",
    "cefrs = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "for i, data_slice in enumerate(data_by_cefr):\n",
    "    if data_slice.empty:\n",
    "        continue\n",
    "    cefr = cefrs[i]\n",
    "    data_slice = data_slice[[\"word\", \"english\", \"type\"]]\n",
    "    data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
    "    data_slice = data_slice[[\"word\", \"english\"]]\n",
    "\n",
    "    #data_slice = data_slice.sort_values('word')\n",
    "    #data_slice = data_slice.rename(columns={'word' : f'word ({cefr})'})\n",
    "\n",
    "    style = data_slice.style.format(\n",
    "        escape=\"latex\",\n",
    "        )\n",
    "    style = style.hide(axis='index')\n",
    "    style = style.hide(axis='columns')\n",
    "\n",
    "    latex = style.to_latex(\n",
    "        environment='supertabular',\n",
    "        column_format=column_format\n",
    "    )\n",
    "\n",
    "    latex_lines = latex.splitlines()\n",
    "\n",
    "    latex = '\\n'.join((map(fix_latex_line, latex_lines)))\n",
    "\n",
    "    filename = f'{DATASET}_two_column_shuffle_{cefr}'\n",
    "    with open(f'build/{filename}.tex', 'w') as f:\n",
    "        f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167571/1458957607.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1458957607.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1458957607.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1458957607.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1458957607.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# two column, cefr by rank\n",
    "data = load_data2()\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data_by_cefr = [\n",
    "    data.iloc[:1000], #A1\n",
    "    data.iloc[1000:2000], #A2\n",
    "    data.iloc[2000:3000], #B1\n",
    "    data.iloc[3000:4000], #B2\n",
    "    data.iloc[4000:], #C1\n",
    "    ]\n",
    "\n",
    "cefrs = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "for i, data_slice in enumerate(data_by_cefr):\n",
    "    if data_slice.empty:\n",
    "        continue\n",
    "    cefr = cefrs[i]\n",
    "    data_slice = data_slice[[\"word\", \"english\", \"type\"]]\n",
    "    data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
    "    data_slice = data_slice[[\"word\", \"english\"]]\n",
    "\n",
    "    data_slice = data_slice.sort_values('word')\n",
    "    #data_slice = data_slice.rename(columns={'word' : f'word ({cefr})'})\n",
    "\n",
    "    style = data_slice.style.format(\n",
    "        escape=\"latex\",\n",
    "        )\n",
    "    style = style.hide(axis='index')\n",
    "    style = style.hide(axis='columns')\n",
    "\n",
    "    latex = style.to_latex(\n",
    "        environment='supertabular',\n",
    "        column_format=column_format\n",
    "    )\n",
    "\n",
    "    latex_lines = latex.splitlines()\n",
    "\n",
    "    latex = '\\n'.join((map(fix_latex_line, latex_lines)))\n",
    "\n",
    "    filename = f'{DATASET}_two_column_alphabetical_{cefr}'\n",
    "    with open(f'build/{filename}.tex', 'w') as f:\n",
    "        f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167571/1689094638.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1689094638.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1689094638.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1689094638.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1689094638.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 4 column with examples alphabetical\n",
    "import re\n",
    "# Fix supertabular and add \\textit to type\n",
    "#column_format = 'p{1.2in}p{2.3in}p{1.2in}p{2.3in}'\n",
    "# 0.787401575 inches margin total\n",
    "# A4 width 8.3 inch\n",
    "#column_format = 'p{1.0in}p{3.0in}p{3.0in}' # total 8.3in - 0.7874in - column_width\n",
    "column_format = 'p{0.8in}p{1.1in}p{2.55in}p{2.55in}' # total 8.3in - 0.7874in - column_width\n",
    "fix_latex_line = FixLatexLine(column_format).fix_latex_line\n",
    "\n",
    "data = load_data2()\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data_by_cefr = [\n",
    "    data.iloc[:1000], #A1\n",
    "    data.iloc[1000:2000], #A2\n",
    "    data.iloc[2000:3000], #B1\n",
    "    data.iloc[3000:4000], #B2\n",
    "    data.iloc[4000:], #C1\n",
    "    ]\n",
    "\n",
    "cefrs = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "for i, data_slice in enumerate(data_by_cefr):\n",
    "    if data_slice.empty:\n",
    "        continue\n",
    "    cefr = cefrs[i]\n",
    "    data_slice = data_slice[[\"word\", \"english\", \"example_spanish\", \"example_english\", \"type\"]]\n",
    "    data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
    "    data_slice = data_slice[[\"word\", \"english\", \"example_spanish\", \"example_english\"]]\n",
    "\n",
    "\n",
    "    data_slice = data_slice.sort_values('word')\n",
    "    #data_slice = data_slice.rename(columns={'word' : f'word ({cefr})'})\n",
    "\n",
    "    style = data_slice.style.format(\n",
    "        escape=\"latex\",\n",
    "        )\n",
    "    style = style.hide(axis='index')\n",
    "    style = style.hide(axis='columns')\n",
    "\n",
    "    latex = style.to_latex(\n",
    "        environment='supertabular',\n",
    "        column_format=column_format\n",
    "    )\n",
    "\n",
    "    latex_lines = latex.splitlines()\n",
    "\n",
    "    latex = '\\n'.join((map(fix_latex_line, latex_lines)))\n",
    "\n",
    "    filename = f'{DATASET}_two_column_alphabetical_{cefr}_with_example'\n",
    "    with open(f'build/{filename}.tex', 'w') as f:\n",
    "        f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_167571/1649978331.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1649978331.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1649978331.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1649978331.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
      "/tmp/ipykernel_167571/1649978331.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n"
     ]
    }
   ],
   "source": [
    "# 4 column with examples shuffle\n",
    "import re\n",
    "# Fix supertabular and add \\textit to type\n",
    "#column_format = 'p{1.2in}p{2.3in}p{1.2in}p{2.3in}'\n",
    "# 0.787401575 inches margin total\n",
    "# A4 width 8.3 inch\n",
    "#column_format = 'p{1.0in}p{3.0in}p{3.0in}' # total 8.3in - 0.7874in - column_width\n",
    "column_format = 'p{0.9in}p{1.0in}p{2.8in}p{2.30in}' # total 8.3in - 0.7874in - column_width\n",
    "fix_latex_line = FixLatexLine(column_format).fix_latex_line\n",
    "#column_format = 'ccc'\n",
    "\n",
    "data = load_data2()\n",
    "data[\"example_spanish\"] = data.apply(lambda row: replace_word_in_field_with_underscore(row.word, row.example_spanish) , axis=1)\n",
    "data_by_cefr = [\n",
    "    data.iloc[:1000], #A1\n",
    "    data.iloc[1000:2000], #A2\n",
    "    data.iloc[2000:3000], #B1\n",
    "    data.iloc[3000:4000], #B2\n",
    "    data.iloc[4000:], #C1\n",
    "    ]\n",
    "\n",
    "cefrs = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
    "for i, data_slice in enumerate(data_by_cefr):\n",
    "    if data_slice.empty:\n",
    "        continue\n",
    "    cefr = cefrs[i]\n",
    "    data_slice = data_slice[[\"word\", \"english\", \"example_spanish\", \"example_english\", \"type\"]]\n",
    "    data_slice[\"word\"] = data_slice.apply(lambda row: f\"{row.word.strip()} ({row.type.strip()})\" , axis=1)\n",
    "    data_slice = data_slice[[\"word\", \"english\", \"example_spanish\", \"example_english\"]]\n",
    "\n",
    "    #data_slice = data_slice.sort_values('word')\n",
    "    #data_slice = data_slice.rename(columns={'word' : f'word ({cefr})'})\n",
    "\n",
    "    style = data_slice.style.format(\n",
    "        escape=\"latex\",\n",
    "        )\n",
    "    style = style.hide(axis='index')\n",
    "    style = style.hide(axis='columns')\n",
    "\n",
    "    latex = style.to_latex(\n",
    "        environment='supertabular',\n",
    "        column_format=column_format\n",
    "    )\n",
    "\n",
    "    latex_lines = latex.splitlines()\n",
    "\n",
    "    latex = '\\n'.join((map(fix_latex_line, latex_lines)))\n",
    "\n",
    "    filename = f'{DATASET}_two_column_shuffle_{cefr}_with_example'\n",
    "    with open(f'build/{filename}.tex', 'w') as f:\n",
    "        f.write(latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Column LateX word,type and definition by CEFR shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run terminal cd format latexmk oxford*.tex to finish build pdfs\n",
    "cmd_build = f\"latexmk -pdf -cd format/{DATASET}*.tex -outdir=../output\" \n",
    "#os.system(cmd_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'format/*.fls': No such file or directory\n",
      "rm: cannot remove 'format/*.log': No such file or directory\n",
      "rm: cannot remove 'format/*.toc': No such file or directory\n",
      "rm: cannot remove 'format/*.synctex*': No such file or directory\n",
      "rm: cannot remove 'format/*.fdb*': No such file or directory\n",
      "rm: cannot remove 'format/*.aux': No such file or directory\n",
      "rm: cannot remove 'format/*.pdf': No such file or directory\n",
      "rm: cannot remove './*.fls': No such file or directory\n",
      "rm: cannot remove './*.log': No such file or directory\n",
      "rm: cannot remove './*.toc': No such file or directory\n",
      "rm: cannot remove './*.synctex*': No such file or directory\n",
      "rm: cannot remove './*.fdb*': No such file or directory\n",
      "rm: cannot remove './*.aux': No such file or directory\n",
      "rm: cannot remove 'output/*.fls': No such file or directory\n",
      "rm: cannot remove 'output/*.log': No such file or directory\n",
      "rm: cannot remove 'output/*.toc': No such file or directory\n",
      "rm: cannot remove 'output/*.synctex*': No such file or directory\n",
      "rm: cannot remove 'output/*.fdb*': No such file or directory\n",
      "rm: cannot remove 'output/*.aux': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean any build files in output/\n",
    "import os\n",
    "files_to_remove = [\"*.fls\", \"*.log\", \"*.toc\", \"*.synctex*\", \"*.fdb*\", \"*.aux\"]\n",
    "cmd_cleanup_output = \"rm \"+\" \".join(f\"output/{f}\" for f in files_to_remove)\n",
    "cmd_cleanup_format = \"rm \"+\" \".join(f\"format/{f}\" for f in files_to_remove+[\"*.pdf\"])\n",
    "cmd_cleanup_main = \"rm \"+\" \".join(f\"./{f}\" for f in files_to_remove)\n",
    "os.system(\";\".join((cmd_cleanup_format, cmd_cleanup_main, cmd_cleanup_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('words')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "18f31073cf804094dd95fd57955d17dd2adebf1ed8efc5124bc1efb23479e449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
